#pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib gspread pandas

import os
import json
import time
import logging
from typing import List, Dict, Optional, Any
from dataclasses import dataclass

import gspread
from google.oauth2.service_account import Credentials
import pandas as pd


@dataclass
class SheetConfig:
    """Configuration for Google Sheets integration"""
    response_sheet_id: str = "1v-QMP93fTGfWuoIM1pGZMKbfcXvUrtjl9reA8JDSJqk"
    admin_sheet_id: str = "1Kq_A2WLDtfboUP6pu9xI3TsNrOpxfCvLcoyFIi8QOxg"
    response_sheet_name: str = "ì„¤ë¬¸ì§€ ì‘ë‹µ ì‹œíŠ¸1"
    copied_sheet_name: str = "Form_Responses(ë°±ì—…)"
    admin_sheet_name: str = "á„‹á…´á„‹á…ªá†¼á„á…¥á†¼á„€á…¨2 A1BL á„‹á…µá†¸á„Œá…®(á„€á…¨á„‹á…£á†¨)á„Œá…¡ á„’á…ªá†¨á„‹á…µá†« á„†á…µá†¾ á„€á…ªá†«á„…á…µá„‰á…µá„á…³(ê´€ë¦¬ì)"
    scopes: List[str] = None
    
    def __post_init__(self):
        if self.scopes is None:
            self.scopes = [
                "https://www.googleapis.com/auth/spreadsheets",
                "https://www.googleapis.com/auth/drive",
            ]


class GoogleSheetsManager:
    """Google Sheets operations manager"""
    
    def __init__(self, config: SheetConfig):
        self.config = config
        self.client = self._setup_client()
        self.logger = self._setup_logger()
        
    def _setup_logger(self) -> logging.Logger:
        """Setup logging configuration"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        return logging.getLogger(__name__)
        
    def _setup_client(self) -> gspread.Client:
        """Setup Google Sheets client with credentials"""
        try:
            creds = Credentials.from_service_account_file("credentials.json", scopes=self.config.scopes)
            return gspread.authorize(creds)
        except Exception as e:
            raise RuntimeError(f"Failed to setup Google Sheets client: {e}")

    def get_worksheet_by_id_with_retry(self, spreadsheet: gspread.Spreadsheet, sheet_id: str, retries: int = 5, delay: int = 1) -> gspread.Worksheet:
        """Get worksheet by ID with retry mechanism"""
        for attempt in range(retries):
            try:
                sheet = spreadsheet.get_worksheet_by_id(sheet_id)
                if sheet:
                    return sheet
            except Exception as e:
                self.logger.warning(f"Attempt {attempt + 1}/{retries} failed: {e}")
                if attempt < retries - 1:
                    time.sleep(delay)
        raise RuntimeError(f"ë³µì‚¬ëœ ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: sheetId={sheet_id}")

    def safe_delete_sheet_by_title(self, spreadsheet: gspread.Spreadsheet, title: str) -> None:
        """Delete sheet by title if it exists"""
        try:
            sheet = spreadsheet.worksheet(title)
            spreadsheet.del_worksheet(sheet)
            self.logger.info(f"ğŸ—‘ ê¸°ì¡´ ì‹œíŠ¸ '{title}' ì‚­ì œ ì™„ë£Œ")
        except gspread.exceptions.WorksheetNotFound:
            self.logger.info(f"ì‹œíŠ¸ '{title}'ê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ ì‚­ì œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")


    def _get_protected_columns(self) -> List[str]:
        """Get protected columns that should not be updated"""
        return [
            "ê²€í† ì1", "ê²€í† ì2", "ë™", "í˜¸ìˆ˜", "íƒ€ì…", "ë¹„ê³ ","ì¹´ì¹´ì˜¤í†¡ ë‹‰ë„¤ì„+uuid"
        ]
    
    def _read_sheets(self) -> tuple[List[Dict], List[Dict], gspread.Worksheet]:
        """Read both response and admin sheets and return their data with admin worksheet"""
        try:
            self.logger.info("ì‘ë‹µ ì‹œíŠ¸ì™€ ê´€ë¦¬ì ì‹œíŠ¸ ì—´ê¸° ì‹œì‘...")
            
            # Open response sheet
            response_sheet = self.client.open_by_key(self.config.response_sheet_id)
            response_ws = response_sheet.worksheet(self.config.response_sheet_name)
            response_data = response_ws.get_all_records()
            self.logger.info(f"âœ… ì‘ë‹µ ì‹œíŠ¸ ì½ê¸° ì™„ë£Œ - {len(response_data)}ê°œ ë ˆì½”ë“œ")
            
            # Open admin sheet
            admin_sheet = self.client.open_by_key(self.config.admin_sheet_id)
            admin_ws = admin_sheet.worksheet(self.config.admin_sheet_name)
            admin_data = admin_ws.get_all_records()
            self.logger.info(f"âœ… ê´€ë¦¬ì ì‹œíŠ¸ ì½ê¸° ì™„ë£Œ - {len(admin_data)}ê°œ ë ˆì½”ë“œ")
            
            # Log sample data for verification
            if response_data:
                self.logger.info(f"ì‘ë‹µ ì‹œíŠ¸ ì»¬ëŸ¼: {list(response_data[0].keys())}")
            if admin_data:
                self.logger.info(f"ê´€ë¦¬ì ì‹œíŠ¸ ì»¬ëŸ¼: {list(admin_data[0].keys())}")
            
            return response_data, admin_data, admin_ws
                
        except Exception as e:
            self.logger.error(f"âŒ ì‹œíŠ¸ ì½ê¸° ì‹¤íŒ¨: {e}")
            raise
    
    def backup_admin_sheet(self, admin_ws: gspread.Worksheet) -> None:
        """Backup admin sheet before processing"""
        try:
            from datetime import datetime
            
            # Create backup sheet name with timestamp
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_name = f"Admin_Backup_{timestamp}"
            
            self.logger.info(f"ê´€ë¦¬ì ì‹œíŠ¸ ë°±ì—… ì‹œì‘: {backup_name}")
            
            # Copy to backup
            copied = admin_ws.copy_to(self.config.admin_sheet_id)
            
            # Get the copied sheet and rename it
            admin_sheet = self.client.open_by_key(self.config.admin_sheet_id)
            copied_ws = self.get_worksheet_by_id_with_retry(admin_sheet, copied["sheetId"])
            copied_ws.update_title(backup_name)
            
            self.logger.info(f"âœ… ê´€ë¦¬ì ì‹œíŠ¸ ë°±ì—… ì™„ë£Œ: {backup_name}")
            
        except Exception as e:
            self.logger.error(f"âŒ ê´€ë¦¬ì ì‹œíŠ¸ ë°±ì—… ì‹¤íŒ¨: {e}")
            raise
    
    def _create_key(self, df: pd.DataFrame) -> pd.DataFrame:
        """Create composite key from ë™ and í˜¸ìˆ˜ columns"""
        df["KEY"] = (
            df["ë™"].astype(str).str.strip() + "-" + 
            df["í˜¸ìˆ˜"].astype(str).str.strip()
        )
        return df
    
    def _get_column_mappings(self) -> Dict[str, str]:
        """Get direct column mappings between response and admin sheets"""
        return {
            "ìœ„ì„ì¥ ì—…ë¡œë“œ": "ìœ„ì„ì¥ ì—…ë¡œë“œ",
            "ê³„ì•½ì„œ ì—…ë¡œë“œ": "ê³„ì•½ì„œ ì—…ë¡œë“œ", 
            "ì´ë¦„": "ì´ë¦„",
            "ë¹„ìƒì—°ë½ë§": "ë¹„ìƒì—°ë½ë§",
            "ë„¤ì´ë²„ì¹´í˜ ID": "ë„¤ì´ë²„ì¹´í˜ ID",
            "ìê²©êµ¬ë¶„": "ìê²©êµ¬ë¶„",
            "ì„¸ëŒ€ ëŒ€í‘œì ì—¬ë¶€": "ì„¸ëŒ€ ëŒ€í‘œì ì—¬ë¶€",
            "ê°œì¸ì •ë³´ ìˆ˜ì§‘Â·ì´ìš© ë™ì˜": "ê°œì¸ì •ë³´ ìˆ˜ì§‘Â·ì´ìš© ë™ì˜"
        }
    
    def _merge_multiline_data(self, existing_value: str, new_values: List[str]) -> str:
        """Merge existing value with new values in multiline format"""
        all_values = []
        
        # Add existing values if any
        if existing_value and str(existing_value).strip():
            existing_lines = [line.strip() for line in str(existing_value).split('\n') if line.strip()]
            all_values.extend(existing_lines)
        
        # Add new values
        for value in new_values:
            value_str = str(value).strip()
            if value_str:
                all_values.append(value_str)
        
        # Remove duplicates while preserving order
        unique_values = []
        seen = set()
        for value in all_values:
            if value not in seen:
                unique_values.append(value)
                seen.add(value)
        
        return '\n'.join(unique_values)
    
    def _extract_representatives(self, responses_for_key: List[Dict]) -> str:
        """Extract representative members based on 'ì„¸ëŒ€ ëŒ€í‘œì ì—¬ë¶€' column"""
        representatives = []
        for response in responses_for_key:
            is_representative = str(response.get('ì„¸ëŒ€ ëŒ€í‘œì ì—¬ë¶€', '')).strip()
            # Check various possible values for representative status
            if is_representative.lower() in ['ì˜ˆ', 'yes', 'y', 'o', 'ëŒ€í‘œ', 'true', '1']:
                name = str(response.get('ì´ë¦„', '')).strip()
                if name:
                    representatives.append(name)
        return '\n'.join(representatives) if representatives else ""
    
    def _generate_uuid_from_df(self, responses_df_for_key: pd.DataFrame) -> str:
        """Generate UUID sequence based on actual response sheet row numbers"""
        if responses_df_for_key.empty:
            return ""
        
        # Get the actual row numbers from the DataFrame index
        # Response sheet row number = DataFrame index + 2 (assuming header in row 1, 0-based index)
        row_numbers = []
        for idx in responses_df_for_key.index:
            actual_row = idx + 2  # Convert 0-based index to 1-based row number, +1 for header
            row_numbers.append(str(actual_row))
        
        self.logger.debug(f"UUID ìƒì„±: DataFrame indices {list(responses_df_for_key.index)} -> í–‰ë²ˆí˜¸ {row_numbers}")
        return '\n'.join(row_numbers)

    def merge_into_admin_sheet(self, response_data, admin_data, admin_ws) -> None:
        """Merge response data into admin sheet"""
        try:
            self.logger.info("ì‘ë‹µ ë°ì´í„°ë¥¼ ê´€ë¦¬ì ì‹œíŠ¸ì— ë³‘í•© ì‹œì‘...")
            
            # Convert to DataFrames
            response_df = pd.DataFrame(response_data)
            admin_df = pd.DataFrame(admin_data)


            if response_df.empty:
                self.logger.warning("âš ï¸ ì‘ë‹µ ì‹œíŠ¸ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë³‘í•©ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                return
            
            self.logger.info(f"Response ì»¬ëŸ¼: {list(response_df.columns)}")
            self.logger.info(f"Admin ì»¬ëŸ¼: {list(admin_df.columns)}")
            
            # Create keys for both dataframes
            response_df = self._create_key(response_df)
            admin_df = self._create_key(admin_df)
            
            # Group response data by KEY (ë™-í˜¸ìˆ˜)
            response_grouped = response_df.groupby('KEY')
            self.logger.info(f"Response ë°ì´í„° ê·¸ë£¹: {len(response_grouped)} ê°œ ë™í˜¸ìˆ˜")
            
            column_mappings = self._get_column_mappings()
            protected_cols = self._get_protected_columns()

            # Process each admin row
            updated_count = 0
            for i, admin_row in admin_df.iterrows():
                key = admin_row['KEY']
                
                if key not in response_grouped.groups:
                    continue
                
                # Get all responses for this ë™í˜¸ìˆ˜
                responses_df_for_key = response_grouped.get_group(key)
                responses_for_key = responses_df_for_key.to_dict('records')
                self.logger.info(f"ë™í˜¸ìˆ˜ {key}: {len(responses_for_key)}ê°œ ì‘ë‹µ ì²˜ë¦¬")
                
                # Generate UUID sequence using actual row numbers
                if 'uuid' in admin_df.columns:
                    admin_df.at[i, 'uuid'] = self._generate_uuid_from_df(responses_df_for_key)
                
                # Extract representatives for  ID
                if 'ëŒ€í‘œì ì´ë¦„' in admin_df.columns:
                    admin_df.at[i, 'ëŒ€í‘œì ì´ë¦„'] = self._extract_representatives(responses_for_key)
                
                # Process each column mapping
                for response_col, admin_col in column_mappings.items():
                    if admin_col in protected_cols:
                        self.logger.debug(f"ë³´í˜¸ëœ ì»¬ëŸ¼ ê±´ë„ˆëœ€: {admin_col}")
                        continue
                    
                    if response_col in response_df.columns and admin_col in admin_df.columns:
                        # Collect all values for this column from responses
                        new_values = [str(resp.get(response_col, '')).strip() for resp in responses_for_key]
                        new_values = [v for v in new_values if v]  # Remove empty values
                        
                        if new_values:
                            existing_value = str(admin_df.at[i, admin_col]) if not pd.isna(admin_df.at[i, admin_col]) else ""
                            merged_value = self._merge_multiline_data(existing_value, new_values)
                            admin_df.at[i, admin_col] = merged_value
                
                updated_count += 1
            
            self.logger.info(f"{updated_count}ê°œ ë™í˜¸ìˆ˜ ë°ì´í„° ë³‘í•© ì™„ë£Œ")

            # Update the sheet
            self._update_admin_sheet(admin_df, admin_ws)
            
        except Exception as e:
            self.logger.error(f"ë°ì´í„° ë³‘í•© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
    

    def _apply_one_time_formatting(self, admin_ws: gspread.Worksheet, start_row: int, num_rows: int, num_cols: int) -> None:
        """One-time formatting: Apply gray background to odd rows with rate limiting"""
        try:
            self.logger.info("ğŸ¨ ì¼íšŒì„± í¬ë§·íŒ…: í™€ìˆ˜ í–‰ì— íšŒìƒ‰ ë°°ê²½ ì ìš© ì¤‘ (170í–‰ë¶€í„° ì¬ì‹œì‘)...")
            
            # Light gray color for alternating rows
            gray_format = {
                "backgroundColor": {
                    "red": 0.95,
                    "green": 0.95, 
                    "blue": 0.95
                }
            }
            
            # Start from row 170 to avoid rate limit issues
            start_from_idx = max(0, 330 - start_row)
            formatted_rows = 0
            
            for row_idx in range(start_from_idx, num_rows):
                actual_row = start_row + row_idx
                
                # Apply to odd rows (1, 3, 5, 7...)
                if actual_row % 2 == 1:
                    start_col_letter = "A"
                    end_col_letter = chr(ord(start_col_letter) + num_cols - 1)
                    range_name = f"{start_col_letter}{actual_row}:{end_col_letter}{actual_row}"
                    
                    try:
                        admin_ws.format(range_name, gray_format)
                        formatted_rows += 1
                        self.logger.info(f"íšŒìƒ‰ ë°°ê²½ ì ìš©: {range_name}")
                        
                        # Rate limiting: wait between requests
                        time.sleep(0.1)  # 100ms delay between each format request
                        
                    except Exception as e:
                        if "quota" in str(e).lower() or "limit" in str(e).lower():
                            self.logger.warning(f"API ì œí•œ ë„ë‹¬, ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                            time.sleep(2)  # Wait 2 seconds on quota error
                            try:
                                admin_ws.format(range_name, gray_format)
                                formatted_rows += 1
                                self.logger.info(f"ì¬ì‹œë„ ì„±ê³µ: {range_name}")
                            except Exception as retry_e:
                                self.logger.error(f"ì¬ì‹œë„ ì‹¤íŒ¨ {range_name}: {retry_e}")
                                break  # Stop formatting on persistent error
                        else:
                            self.logger.warning(f"í¬ë§·íŒ… ì‹¤íŒ¨ {range_name}: {e}")
            
            self.logger.info(f"âœ… ì¼íšŒì„± í¬ë§·íŒ… ì™„ë£Œ: {formatted_rows}ê°œ í™€ìˆ˜ í–‰ì— íšŒìƒ‰ ë°°ê²½ ì ìš© (170í–‰ë¶€í„°)")
            
        except Exception as e:
            self.logger.error(f"ì¼íšŒì„± í¬ë§·íŒ… ì¤‘ ì˜¤ë¥˜: {e}")
            # í¬ë§·íŒ… ì‹¤íŒ¨í•´ë„ ë°ì´í„°ëŠ” ì •ìƒ ì—…ë°ì´íŠ¸ëœ ìƒíƒœ

    def _update_admin_sheet(self, admin_df: pd.DataFrame, admin_ws: gspread.Worksheet) -> None:
        """Update admin sheet with merged data - use existing DataFrame structure"""
        try:
            self.logger.info("ê´€ë¦¬ì ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹œì‘...")
            
            # Remove KEY column for update
            update_df = admin_df.drop(columns=['KEY'], errors='ignore')
            
            # Debug: Log columns and sample data
            self.logger.info(f"ì—…ë°ì´íŠ¸í•  DataFrame ì»¬ëŸ¼: {list(update_df.columns)}")
            if not update_df.empty:
                self.logger.info(f"ìƒ˜í”Œ ë°ì´í„° (ì²«ë²ˆì§¸ í–‰):")
                for col in update_df.columns:
                    sample_value = update_df.iloc[0][col]
                    if str(sample_value).strip():  # Only log non-empty values
                        self.logger.info(f"  {col}: '{sample_value}'")
            
            # Prepare update values
            update_values = []
            for _, row in update_df.iterrows():
                row_values = []
                for col in update_df.columns:
                    val = row[col]
                    val_str = "" if pd.isna(val) else str(val)
                    row_values.append(val_str)
                update_values.append(row_values)
            
            if not update_values:
                self.logger.warning("ì—…ë°ì´íŠ¸í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # Calculate update range - find where data actually starts
            # First, check the sheet structure
            all_data = admin_ws.get_all_values()
            self.logger.info(f"ì‹œíŠ¸ ì „ì²´ êµ¬ì¡° (ì²˜ìŒ 5í–‰):")
            for i, row in enumerate(all_data[:5], 1):
                self.logger.info(f"  í–‰ {i}: {row}")
            
            # Find the header row (contains column names)
            header_row_idx = None
            for i, row in enumerate(all_data):
                if any('ë™' in str(cell) and 'í˜¸ìˆ˜' in str(all_data[i]) for cell in row):
                    header_row_idx = i + 1  # Convert to 1-based
                    break
            
            if header_row_idx is None:
                # Fallback to default
                header_row_idx = 3
                self.logger.warning("í—¤ë” í–‰ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ê°’(3í–‰) ì‚¬ìš©")
            
            # Data starts right after header
            start_row = header_row_idx + 1
            start_col = "A"
            end_col = chr(ord(start_col) + len(update_df.columns) - 1)
            end_row = start_row + len(update_values) - 1
            range_name = f"{start_col}{start_row}:{end_col}{end_row}"
            
            self.logger.info(f"ğŸŸ¢ í—¤ë” í–‰: {header_row_idx}, ë°ì´í„° ì‹œì‘: {start_row}")
            self.logger.info(f"ğŸŸ¢ ì—…ë°ì´íŠ¸ ë²”ìœ„: {range_name} ({len(update_values)}í–‰ x {len(update_df.columns)}ì—´)")
            
            # Update the sheet
            admin_ws.update(range_name=range_name, values=update_values)
            
            # One-time formatting: Apply alternating gray colors to odd rows
            # self._apply_one_time_formatting(admin_ws, start_row, len(update_values), len(update_df.columns))
            
            self.logger.info("âœ… ê´€ë¦¬ì ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
    
    def process_sheets(self) -> None:
        """Main method to process both copy and merge operations"""
        self.logger.info("Google Sheets ì²˜ë¦¬ ì‹œì‘")

        # File load confirmation
        try:
            self.logger.info("Credentials íŒŒì¼ í™•ì¸ ì¤‘...")
            # Test connection by opening a sheet
            test_sheet = self.client.open_by_key(self.config.response_sheet_id)
            self.logger.info(f"âœ… Credentials ë¡œë“œ ì„±ê³µ - ì‹œíŠ¸ '{test_sheet.title}' ì ‘ê·¼ í™•ì¸")
        except Exception as e:
            self.logger.error(f"âŒ Credentials ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
        
        # Test reading both sheets
        response_data, admin_data, admin_ws = self._read_sheets()
        self.logger.info(f"ì‹œíŠ¸ ì½ê¸° í…ŒìŠ¤íŠ¸ ì™„ë£Œ - ì‘ë‹µ: {len(response_data)}ê°œ, ê´€ë¦¬ì: {len(admin_data)}ê°œ ë ˆì½”ë“œ")
        
        # Backup admin sheet before processing
        self.backup_admin_sheet(admin_ws)
        
        self.merge_into_admin_sheet(response_data,admin_data,admin_ws)
        self.logger.info("Google Sheets ì²˜ë¦¬ ì™„ë£Œ")


def main():
    """Main function to run the Google Sheets processing"""
    try:
        config = SheetConfig()
        manager = GoogleSheetsManager(config)
        manager.process_sheets()
    except Exception as e:
        logging.error(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise


if __name__ == "__main__":
    main()
